{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5PZXBjOwnTC"
   },
   "source": [
    "# **SME0142 - Álgebra Linear e Aplicações**\n",
    "Docente: Cynthia de Oliveira Lage Ferreira\n",
    "\n",
    "\n",
    "# **Trabalho Prático**\n",
    "Outubro de 2025\n",
    "\n",
    "# Alunos: Daniel Jorge Manzano & Nicolas Amaral dos Santos\n",
    "\n",
    "# Orientações Gerais\n",
    "\n",
    "*   Esta avaliação é **individual ou em dupla** e deverá ser desenvolvida na plataforma Colab (https://colab.research.google.com/).\n",
    "\n",
    "*   Cada aluno/dupla deverá produzir um arquivo .ipynb contendo as soluções dos exercícios. Sejam organizados !\n",
    "\n",
    "*   Os arquivos deverão estar identificados por **NOMEDOALUNO1NoUSP-NOMEDOALUNO2NoUSP.ipynb** a fim de facilitar a organização das atividades pela professora.\n",
    "\n",
    "*  Os arquivos deverão ser enviados **até às 20h do dia 18/10/2025** através da plataforma e-disciplinas da USP (https://edisciplinas.usp.br/). **Os arquivos recebidos por e-mail não serão corrigidos.** Arquivos enviados fora do prazo também não serão corrigidos!\n",
    "\n",
    "*   Apenas os alunos que estiverem com a **situação regularizada no Sistema Jupiter** terão suas avaliações corrigidas.\n",
    "\n",
    "*  Todos os códigos utilizados para resolver os problemas deverão ser apresentados, executados e minimamente comentados. **Questões com respostas sem justificativas não serão consideradas.**\n",
    "\n",
    "**BOM TRABALHO!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5BexU-0dxZQ5"
   },
   "outputs": [],
   "source": [
    "#Bibliotecas Utilizadas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug43yvau01qY"
   },
   "source": [
    "# **Exercício 1**\n",
    "Considere o espaço vetorial real $\\mathbb{R}^2$. Sejam as transformações\n",
    "- $T_1:\\mathbb{R}^2 \\to \\mathbb{R}^2$ tal que $T_1(x,y)=(-x,y)$ - **reflexão em torno do eixo $oy$**;\n",
    "- $T_2:\\mathbb{R}^2 \\to \\mathbb{R}^2$ tal que a matriz da transformação é dada por\n",
    "$$[T_2] = \\begin{bmatrix} 1 & k \\\\ 0 & 1 \\end{bmatrix},$$\n",
    "com $k\\in\\mathbb{R}$ - **cisalhamento horizontal**.\n",
    "\n",
    "a) Aplique as transformações $T_1$ e $T_2$ no quadrado de vértices $(0,0)$, $(1,0)$, $(1,1)$ e $(0,1)$ considerando o parâmetro $k= -0,5$ e visualize os resultados.\n",
    "\n",
    "b) Determine a matriz da transformação $T_3$ que primeiro faz um cisalhamento horizontal com $k=-0.5$ mapeando $e_2$ em $e_2 - 0.5e_1$ ($e_1$ se mantém inalterado) e então reflete o resultado em torno do eixo $oy$. **Dica:** Determine a posição final das imagens de $e_1$ e $e_2$.\n",
    "\n",
    "c) Qual a relação entre as matrizes $[T_1]$, $[T_2]$ e a matriz da transformação $[T_3]$ obtida no item anterior?\n",
    "\n",
    "d) Determine a transformação de reflexão em torno do eixo $ox$ e a transformação de cisalhamento vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8hPXtW8LmLLU"
   },
   "outputs": [],
   "source": [
    "# Código letra A\n",
    "\n",
    "# Solução 1\n",
    "# Vértices do quadrado\n",
    "Q = np.array([[0,0],[1,0],[1,1],[0,1]]).T\n",
    "\n",
    "# Reflexão em torno do eixo y\n",
    "# (-x,y) = x(-1,0) + y(0,1)\n",
    "T1 = np.array([[-1, 0], [0, 1]])\n",
    "\n",
    "# Cisalhamento horizontal k = -0.5\n",
    "k = -0.5\n",
    "T2 = np.array([[1, k], [0, 1]])\n",
    "\n",
    "# Aplicando as transformações\n",
    "T1Q = T1 @ Q\n",
    "T2Q = T1 @ Q\n",
    "\n",
    "def plotSimples(vx, vy):\n",
    "  plt.figure(figsize=(6,6))\n",
    "  plt.axis([-2, 2, -2, 2])\n",
    "  plt.plot([-2,2], [0,0], 'k--', alpha=0.75)\n",
    "  plt.plot([0,0], [-2,2],'k--', alpha=0.75)\n",
    "  plt.plot(vx, vy, 'k')\n",
    "  plt.plot([vx[0], vx[-1]], [vy[0], vy[-1]], 'k')\n",
    "  plt.plot(vx, vy, 'bo')\n",
    "  plt.grid(True)\n",
    "\n",
    "# Plots (para ver o plot no próprio notebook, comentar as linhas com \"plt.close()\"; por padrão, eles são salvos e não aparecem no notebook)\n",
    "plotSimples(Q[0,:], Q[1,:])\n",
    "plt.title('Vértices originais')\n",
    "plt.savefig(\"1a_vertices_originais.png\")\n",
    "plt.close()\n",
    "\n",
    "plotSimples(T1Q[0,:], T1Q[1,:])\n",
    "plt.title('Reflexão')\n",
    "plt.savefig(\"1a_reflexao.png\")\n",
    "plt.close()\n",
    "\n",
    "plotSimples(T2Q[0,:], T2Q[1,:])\n",
    "plt.title('Cisalhamento')\n",
    "plt.savefig(\"1a_cisalhamento.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eVC3sD1Wmj00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Solução 2 ---\n",
      "Matriz T3 encontrada pela observação dos vetores da base:\n",
      "[[-1.   0.5]\n",
      " [ 0.   1. ]]\n",
      "\n",
      "--- Solução 3 ---\n",
      "Verificando T3 pelo produto T1 @ T2:\n",
      "[[-1.   0.5]\n",
      " [ 0.   1. ]]\n",
      "Os resultados são iguais, como esperado.\n"
     ]
    }
   ],
   "source": [
    "# Código letra B\n",
    "\n",
    "#Solução 2)\n",
    "# Observando as posições finais de e1 e e2 temos:\n",
    "# T3(1,0) = (-1,0)\n",
    "# T3(0,1) = (0.5,1)\n",
    "T3 = np.array([[-1, 0.5], [0, 1]])\n",
    "print(\"--- Solução 2 ---\")\n",
    "print(\"Matriz T3 encontrada pela observação dos vetores da base:\")\n",
    "print(T3)\n",
    "\n",
    "# Código letra C\n",
    "\n",
    "# Solução 3)\n",
    "# Por outro lado, aplicando T2, depois T1\n",
    "print(\"\\n--- Solução 3 ---\")\n",
    "print(\"Verificando T3 pelo produto T1 @ T2:\")\n",
    "T1_vezes_T2 = T1 @ T2\n",
    "print(T1_vezes_T2)\n",
    "print(\"Os resultados são iguais, como esperado.\")\n",
    "\n",
    "# Código letra D\n",
    "\n",
    "# Solução 4)\n",
    "# Reflexão em torno do eixo x\n",
    "T4 = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# Cisalhamento vertical: (x, y) -> (x, y + kx) com k = -0.5\n",
    "T5 = np.array([[1, 0], [-0.5, 1]])\n",
    "\n",
    "# Aplicando as transformações\n",
    "T4Q = T4 @ Q\n",
    "T5Q = T5 @ Q\n",
    "\n",
    "# Plots (assim como os plots anteriores, comentar as linhas com \"plt.close()\" para ver o plot no notebook)\n",
    "plotSimples(T4Q[0,:], T4Q[1,:])\n",
    "plt.title('Reflexão em x')\n",
    "plt.savefig(\"1d_reflexao_x.png\")\n",
    "plt.close()\n",
    "\n",
    "plotSimples(T5Q[0,:], T5Q[1,:])\n",
    "plt.title('Cisalhamento vertical')\n",
    "plt.savefig(\"1d_cisalhamento_vertical.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9OlCLzSzhkJ"
   },
   "source": [
    "# **Exercício 2**\n",
    "Considere a transformação $T:R^7 \\rightarrow R^3$ linear dada pela matriz\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{ccccccc}\n",
    "3 & 9 & 6 & 6 & 9 & 3 & 1\\\\\n",
    "2 & 0 & 9 & 2 & 0 & 5 & 3\\\\\n",
    "0 & 0 & 1 & 0 & 1 & 0 & 2\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "a) Qual a dimensão do núcleo e da imagem da transformação? Faça um código para determinar a dimensão da imagem e conclua, então, a dimensão do núcleo.\n",
    "\n",
    "b) Encontre uma base para o espaço núcleo.\n",
    "\n",
    "c) Faça um código para verificar que a base encontrada está gerando o núcleo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZPSn2rAPkyM2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTÃO A ----\n",
      "Dimensão da imagem: 3\n",
      "Dimensão do núcleo: 4\n",
      "\n",
      "QUESTÃO B ----\n",
      "Base do núcleo:\n",
      "⎡                         ⎡15/2⎤⎤\n",
      "⎢⎡ -1 ⎤  ⎡ 9/2 ⎤  ⎡-5/2⎤  ⎢    ⎥⎥\n",
      "⎢⎢    ⎥  ⎢     ⎥  ⎢    ⎥  ⎢-23 ⎥⎥\n",
      "⎢⎢-1/3⎥  ⎢-11/6⎥  ⎢1/2 ⎥  ⎢────⎥⎥\n",
      "⎢⎢    ⎥  ⎢     ⎥  ⎢    ⎥  ⎢ 18 ⎥⎥\n",
      "⎢⎢ 0  ⎥  ⎢ -1  ⎥  ⎢ 0  ⎥  ⎢    ⎥⎥\n",
      "⎢⎢    ⎥  ⎢     ⎥  ⎢    ⎥  ⎢ -2 ⎥⎥\n",
      "⎢⎢ 1  ⎥, ⎢  0  ⎥, ⎢ 0  ⎥, ⎢    ⎥⎥\n",
      "⎢⎢    ⎥  ⎢     ⎥  ⎢    ⎥  ⎢ 0  ⎥⎥\n",
      "⎢⎢ 0  ⎥  ⎢  1  ⎥  ⎢ 0  ⎥  ⎢    ⎥⎥\n",
      "⎢⎢    ⎥  ⎢     ⎥  ⎢    ⎥  ⎢ 0  ⎥⎥\n",
      "⎢⎢ 0  ⎥  ⎢  0  ⎥  ⎢ 1  ⎥  ⎢    ⎥⎥\n",
      "⎢⎢    ⎥  ⎢     ⎥  ⎢    ⎥  ⎢ 0  ⎥⎥\n",
      "⎢⎣ 0  ⎦  ⎣  0  ⎦  ⎣ 0  ⎦  ⎢    ⎥⎥\n",
      "⎣                         ⎣ 1  ⎦⎦\n",
      "\n",
      "QUESTÃO C ----\n",
      "Os vetores da base pertencem ao núcleo? True\n",
      "Os vetores da base são linearmente independentes? True\n",
      "Portanto, a base encontrada gera o núcleo.\n"
     ]
    }
   ],
   "source": [
    "B = np.asarray([[3, 9, 6, 6, 9, 3, 1],\n",
    "                [2, 0, 9, 2, 0, 5, 3],\n",
    "                [0, 0, 1 , 0, 1, 0, 2]])\n",
    "\n",
    "\n",
    "# a) ----------------------- //\n",
    "print(\"QUESTÃO A ----\")\n",
    "\n",
    "# calcular a dimensão da imagem\n",
    "dim_imagem = np.linalg.matrix_rank(B)\n",
    "print(f\"Dimensão da imagem: {dim_imagem}\")\n",
    "\n",
    "# sabendo que dim(domínio) = dim(imagem) + dim(núcleo), calculamos, também, a dimensão do núcleo\n",
    "dim_nucleo = B.shape[1] - dim_imagem # 'B.shape[1]' nos dá o número de colunas\n",
    "print(f\"Dimensão do núcleo: {dim_nucleo}\")\n",
    "\n",
    "\n",
    "# b) ----------------------- //\n",
    "print(\"\\nQUESTÃO B ----\")\n",
    "\n",
    "import sympy as sp # para não recorrer a métodos numéricos (usando numpy) podemos usar o sympy\n",
    "\n",
    "B_sp = sp.Matrix(B) # converte B para o formato do sympy. usamos para aplicar o .nullspace(), que encontra os vetores da base do núcleo\n",
    "base_nucleo = B_sp.nullspace() \n",
    "print(\"Base do núcleo:\")\n",
    "sp.pprint(base_nucleo)\n",
    "\n",
    "\n",
    "# c) ----------------------- //\n",
    "print(\"\\nQUESTÃO C ----\")\n",
    "\n",
    "# para verificar se a base encontrada gera o núcleo, devemos:\n",
    "# 1. verificar se cada vetor da base, quando multiplicamos pela matriz B, resulta no vetor nulo\n",
    "# 2. verificar se os vetores são linearmente independentes\n",
    "\n",
    "# 1. aplica-se o np.allclose (comparando com um vetor nulo como resultado) sobre cada vetor da base para verificar se B @ v = 0\n",
    "pertencem_ao_nucleo = [np.allclose(B @ np.array(v).astype(np.float64), np.zeros(B.shape[0])) for v in base_nucleo]\n",
    "print(\"Os vetores da base pertencem ao núcleo?\", all(pertencem_ao_nucleo))\n",
    "\n",
    "# 2. verifica-se a independência linear calculando a dimensão da base do núcleo (converte a matriz para o formato numpy e calcula numericamente)\n",
    "matriz_base = np.array(base_nucleo).astype(np.float64).reshape(len(base_nucleo), -1)\n",
    "rank_base = np.linalg.matrix_rank(matriz_base)\n",
    "sao_li = (rank_base == len(base_nucleo)) # se a dimensão é igual ao número de vetores, são LI\n",
    "print(\"Os vetores da base são linearmente independentes?\", sao_li)\n",
    "\n",
    "if (all(pertencem_ao_nucleo) & sao_li): print(\"Portanto, a base encontrada gera o núcleo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Cu3SshMxa7K"
   },
   "source": [
    "# **Exercício 3**\n",
    "\n",
    "a) Dada uma base qualquer de um subespaço vetorial do $R^{n}$, escreva um código para encontrar uma base ortonormal para este subespaço. Teste o seu código para a base dada pelas colunas da matriz  **V**  gerada no código abaixo.\n",
    "\n",
    "b) Faça um teste para verificar que a base obtida é de fato ortonormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ss1xiAdxo74",
    "outputId": "251ae907-8c7e-44c8-96a3-98010505ed77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  5 13  2 18  7 13  0 13 11]\n",
      " [19 13  9  5 15  3  3 11 17  4]\n",
      " [18  5 17  3  3 13  8 14 10 18]\n",
      " [ 0  8 10 18 18 15  1  1  5 13]\n",
      " [13  7  0  2 17  0 15  1 10 19]\n",
      " [ 9 14  5 13 11 18  9  0 12  6]\n",
      " [17  3  8  5  3  7 10 16  8  1]\n",
      " [15  0  9 15 19  3 15  8 13  7]\n",
      " [ 4  7  1  9 15 13  1 15  8  4]\n",
      " [ 4  5 17 10 14 17 15 10  4 18]\n",
      " [ 9  7  0  3  9 15 16 11 11  6]\n",
      " [ 7  2  2  2  2 17 19  1 16 14]\n",
      " [ 2  8 15  5 13  2 15  8  2 10]\n",
      " [ 0 16 12  3 17 18  1 13 16 13]\n",
      " [10  6 10  5 10  7 10 19 17  5]\n",
      " [17  0  1 14  4 10 11 11  1  4]\n",
      " [19 17 12 15 14 18  6  2 15 14]\n",
      " [19  7  2 10  5  3 17 19 19 19]\n",
      " [13  0  2  2 15 18  2 15 12  2]\n",
      " [10 16 19 11  4  4 19  9  8 17]]\n"
     ]
    }
   ],
   "source": [
    "V = np.random.randint(0,20,size=(20,10))\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "r5iDnSwDx19x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Base Ortonormal Q (Letra a) ---\n",
      "A matriz resultante tem dimensões: (20, 10)\n",
      "\n",
      "Mostrando as primeiras 5 linhas e 5 colunas:\n",
      "[[ 0.24783614 -0.05106736  0.24459319 -0.23569611  0.32037856]\n",
      " [ 0.33634904  0.13597604 -0.14460016 -0.24725636  0.07384019]\n",
      " [ 0.31864646 -0.11284925  0.3616125  -0.2679772  -0.23850212]\n",
      " [ 0.          0.26427076  0.16164886  0.54938346  0.16336101]\n",
      " [ 0.23013356  0.0304458  -0.27625927 -0.15473069  0.36079699]]\n",
      "--- Verificação da Ortronormalidade (Letra b) ---\n",
      "\n",
      "Resultado do produto Q.T @ Q:\n",
      "[[ 1. -0. -0.  0. -0. -0. -0. -0.  0.  0.]\n",
      " [-0.  1.  0.  0.  0. -0.  0.  0.  0. -0.]\n",
      " [-0.  0.  1.  0.  0.  0.  0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  1. -0.  0.  0. -0. -0. -0.]\n",
      " [-0.  0.  0. -0.  1. -0. -0.  0.  0. -0.]\n",
      " [-0. -0.  0.  0. -0.  1. -0.  0.  0.  0.]\n",
      " [-0.  0.  0.  0. -0. -0.  1.  0.  0.  0.]\n",
      " [-0.  0.  0. -0.  0.  0.  0.  1.  0. -0.]\n",
      " [ 0.  0.  0. -0.  0.  0.  0.  0.  1. -0.]\n",
      " [ 0. -0. -0. -0. -0.  0.  0. -0. -0.  1.]]\n",
      "\n",
      "O resultado do teste np.allclose(QT_Q, Identidade) é: True\n",
      "\n",
      "Conclusão: O teste confirma que a base é ortonormal.\n"
     ]
    }
   ],
   "source": [
    "# a) Ortonormalização de uma base qualquer dada e teste do código em V\n",
    "\n",
    "def gram_schmidt(A):\n",
    "    \"\"\"\n",
    "    Aplica o processo de ortonormalização de Gram-Schmidt às colunas de uma matriz A.\n",
    "    Parâmetros: A (np.array): Matriz cujas colunas formam a base a ser ortonormalizada.\n",
    "    Retorna: Q (np.array): Matriz com colunas ortonormais que formam uma base para o mesmo subespaço.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pega as dimensões da matriz de entrada\n",
    "    n_linhas, n_cols = A.shape\n",
    "    \n",
    "    # Cria uma matriz de zeros para armazenar a base ortonormal resultante (Q)\n",
    "    Q = np.zeros_like(A, dtype=float)\n",
    "    \n",
    "    # Itera sobre cada coluna/vetor da matriz A\n",
    "    for i in range(n_cols):\n",
    "        # Pega o vetor v_i atual\n",
    "        v = A[:, i].astype(float)\n",
    "        \n",
    "        # Inicia o processo de ortogonalização: u_i = v_i - proj(v_i) sobre os q_j's anteriores\n",
    "        # Começamos com u = v e subtraímos as projeções\n",
    "        u = v.copy()\n",
    "        for j in range(i):\n",
    "            q_j = Q[:, j]\n",
    "            # Coeficiente da projeção de v sobre q_j: (v . q_j)\n",
    "            # Como q_j já é unitário, não precisamos dividir pela sua norma ao quadrado.\n",
    "            proj_coeff = np.dot(v, q_j)\n",
    "            # Subtrai a projeção de u\n",
    "            u -= proj_coeff * q_j\n",
    "            \n",
    "        # Normalização: transforma o vetor ortogonal u em um vetor unitário q\n",
    "        # Calcula a norma (comprimento) do vetor u\n",
    "        norma_u = np.linalg.norm(u)\n",
    "        \n",
    "        # Evita divisão por zero se o vetor for nulo (o que indica vetores L.D. na entrada)\n",
    "        if norma_u > 1e-10:\n",
    "            Q[:, i] = u / norma_u\n",
    "            \n",
    "    return Q\n",
    "\n",
    "\n",
    "# Aplica a função de Gram-Schmidt na matriz V\n",
    "Q = gram_schmidt(V)\n",
    "\n",
    "# Imprime o resultado para verificação\n",
    "print(\"--- Base Ortonormal Q (Letra a) ---\")\n",
    "print(\"A matriz resultante tem dimensões:\", Q.shape)\n",
    "print(\"\\nMostrando as primeiras 5 linhas e 5 colunas:\")\n",
    "print(Q[:5, :5])\n",
    "\n",
    "\n",
    "# b) Teste que verifica se a base obtida é de fato ortonormal\n",
    "\n",
    "print(\"--- Verificação da Ortronormalidade (Letra b) ---\")\n",
    "\n",
    "# 1. Calcular o produto da transposta de Q pela própria matriz Q.\n",
    "QT_Q = Q.T @ Q\n",
    "\n",
    "print(\"\\nResultado do produto Q.T @ Q:\")\n",
    "# Arredondamos o resultado para 10 casas decimais para facilitar a visualização.\n",
    "print(np.round(QT_Q, decimals=10))\n",
    "\n",
    "# 2. Verificar se o resultado é a Matriz Identidade.\n",
    "# Criamos a matriz identidade do tamanho correto (10x10, pois Q tem 10 colunas).\n",
    "identidade = np.identity(Q.shape[1])\n",
    "\n",
    "# allclose retorna True se as matrizes são \"suficientemente próximas\".\n",
    "e_ortonormal = np.allclose(QT_Q, identidade)\n",
    "\n",
    "print(f\"\\nO resultado do teste np.allclose(QT_Q, Identidade) é: {e_ortonormal}\")\n",
    "\n",
    "# 3. Imprimir uma conclusão clara\n",
    "if e_ortonormal:\n",
    "    print(\"\\nConclusão: O teste confirma que a base é ortonormal.\")\n",
    "else:\n",
    "    print(\"\\nConclusão: O teste falhou. A base NÃO é ortonormal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLAkl8MVW1WE"
   },
   "source": [
    "# **Exercício 4**\n",
    "\n",
    "\n",
    "Considere a seguinte rede não direcionada composta por 12 nós, com conexões definidas pela matriz de adjacência abaixo (os nós estão numerados de 1 a 12).\n",
    "\n",
    "A rede foi construída com o objetivo de evidenciar a diferença entre duas medidas de centralidade: **centralidade de grau** e **centralidade de autovalor**.\n",
    "\n",
    "### **Matriz de Adjacência**\n",
    "\n",
    "A matriz a seguir é referente a rede considerada. Um valor $1$ na posição $(i,j)$ indica uma conexão entre os nós $i$ e $j$; $0$ indica ausência de conexão.\n",
    "\n",
    "\n",
    "\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Com base na estrutura da rede acima, realize as seguintes tarefas:\n",
    "\n",
    "    \n",
    "\n",
    "a)   Calcule a centralidade de grau para cada nó. Liste os nós com maior centralidade de grau.\n",
    "\n",
    "b)   Calcule a centralidade de autovalor para cada nó. Liste os nós com maior centralidade de autovalor.\n",
    "\n",
    "c)   Há nós com alta centralidade de grau mas baixa centralidade de autovalor? Justifique com base na estrutura da rede.\n",
    "\n",
    "\n",
    "d)   Há nós com baixa centralidade de grau mas alta centralidade de autovalor? Explique o motivo.\n",
    "\n",
    "e)   Discuta as diferenças entre as duas centralidades à luz dos resultados obtidos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rKQ6rpVxFK_V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Respostas para (a) e (b) ---\n",
      "Centralidades dos nós:\n",
      "\n",
      "      Grau  Autovalor\n",
      "1   0.4545     0.3976\n",
      "2   0.4545     0.3976\n",
      "3   0.4545     0.3976\n",
      "4   0.4545     0.3976\n",
      "5   0.5455     0.3944\n",
      "6   0.9091     0.4141\n",
      "7   0.0909     0.0823\n",
      "8   0.0909     0.0823\n",
      "9   0.0909     0.0823\n",
      "10  0.0909     0.0823\n",
      "11  0.0909     0.0823\n",
      "12  0.0909     0.0823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLetras C, D, E: Justificativas e Discussão\\n\\nC) Há nós com alta centralidade de grau mas baixa centralidade de autovalor?\\n\\nNão. Nesta rede, os nós com alta centralidade de grau (nós 1 a 6) são também os que possuem os maiores valores de centralidade de autovalor.\\nJustificativa: Os nós de 1 a 5 formam um grupo densamente conectado (clique) e estão ligados ao nó 6, que é a ponte para o resto da rede.\\nO nó 6, por sua vez, possui o maior número de conexões. Devido a essa estrutura, todos os nós com muitas conexões são, por definição, influentes \\ne bem posicionados, resultando também em alta centralidade de autovalor.\\n\\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nD) Há nós com baixa centralidade de grau mas alta centralidade de autovalor?\\n\\nSim. Os nós de 7 a 12 se encaixam perfeitamente nesta descrição.\\nMotivo: Cada um desses nós possui o menor grau possível na rede (grau 1), o que resulta em uma centralidade de grau muito baixa. \\nNo entanto, a única conexão que eles possuem é com o nó 6, que é o nó mais influente e central de toda a rede. \\nAo estarem conectados a um nó tão importante, eles \"herdam\" parte dessa influência, o que eleva sua centralidade de autovalor a um nível\\nconsideravelmente mais alto do que seu baixo grau sugeriria.\\n\\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nE) Discuta as diferenças entre as duas centralidades à luz dos resultados obtidos.\\n\\nOs resultados desta rede evidenciam a diferença fundamental entre as duas métricas:\\n\\n- Centralidade de Grau: É uma medida de popularidade local, simplesmente contando o NÚMERO de conexões diretas. O nó 6 é o vencedor claro com 7 conexões, \\nenquanto os nós 7-12 são os \"perdedores\" com apenas 1 conexão cada.\\n\\n- Centralidade de Autovalor: É uma medida de influência, que considera a QUALIDADE das conexões. Ela responde à pergunta \"quão importantes são seus vizinhos?\".\\nO nó 6 é o mais influente por conectar os dois principais agrupamentos da rede. Os nós 7-12, apesar de terem poucas conexões, demonstram uma influência significativa (autovalor de ~0.24)\\nporque estão ligados ao nó mais importante.\\nEm resumo, o exercício mostra que um nó não precisa ter muitas conexões para ser influente, desde que suas poucas conexões sejam com os nós certos.\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Criar o grafo\n",
    "G_temp = nx.from_numpy_array(A) # Grafo temporário a partir da matriz A\n",
    "G = nx.relabel_nodes(G_temp, {i: i + 1 for i in range(12)}) # Renomeia os nós de 0-11 para 1-12, criando o grafo final G\n",
    "\n",
    "# Código letras A e B: Cálculo e listagem das centralidades\n",
    "\n",
    "# Calcular centralidades\n",
    "deg_centrality = nx.degree_centrality(G) # # Calcula a centralidade de grau para todos os nós do grafo G\n",
    "eig_centrality = nx.eigenvector_centrality(G, max_iter=1000) # Calcula a centralidade de autovalor para todos os nós\n",
    "\n",
    "# Exibir tabela com os valores calculados para cada nó\n",
    "centrality_df = pd.DataFrame({\n",
    "    \"Grau\": deg_centrality,\n",
    "    \"Autovalor\": eig_centrality\n",
    "}).sort_index().round(4)\n",
    "\n",
    "\n",
    "print(\"--- Respostas para (a) e (b) ---\")\n",
    "print(\"Centralidades dos nós:\\n\")\n",
    "print(centrality_df)\n",
    "\n",
    "# Visualizar o grafo\n",
    "plt.figure(figsize=(10, 10))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "node_sizes = [v * 5000 for v in deg_centrality.values()]\n",
    "node_colors = list(eig_centrality.values())\n",
    "\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.viridis)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.6)\n",
    "nx.draw_networkx_labels(G, pos, font_color='white', font_weight='bold')\n",
    "\n",
    "plt.title(\"Rede: Tamanho por Grau, Cor por Autovalor\")\n",
    "\n",
    "cbar = plt.colorbar(nodes)\n",
    "\n",
    "cbar.set_label(\"Centralidade de Autovalor\", rotation=270, labelpad=15)\n",
    "\n",
    "plt.savefig(\"4ab_grafo_centralidades.png\")\n",
    "plt.close() # para visualizar o grafo no notebook, comentar esta linha\n",
    "\n",
    "\"\"\"\n",
    "Letras C, D, E: Justificativas e Discussão\n",
    "\n",
    "C) Há nós com alta centralidade de grau mas baixa centralidade de autovalor?\n",
    "\n",
    "Não. Nesta rede, os nós com alta centralidade de grau (nós 1 a 6) são também os que possuem os maiores valores de centralidade de autovalor.\n",
    "Justificativa: Os nós de 1 a 5 formam um grupo densamente conectado (clique) e estão ligados ao nó 6, que é a ponte para o resto da rede.\n",
    "O nó 6, por sua vez, possui o maior número de conexões. Devido a essa estrutura, todos os nós com muitas conexões são, por definição, influentes \n",
    "e bem posicionados, resultando também em alta centralidade de autovalor.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "D) Há nós com baixa centralidade de grau mas alta centralidade de autovalor?\n",
    "\n",
    "Sim. Os nós de 7 a 12 se encaixam perfeitamente nesta descrição.\n",
    "Motivo: Cada um desses nós possui o menor grau possível na rede (grau 1), o que resulta em uma centralidade de grau muito baixa. \n",
    "No entanto, a única conexão que eles possuem é com o nó 6, que é o nó mais influente e central de toda a rede. \n",
    "Ao estarem conectados a um nó tão importante, eles \"herdam\" parte dessa influência, o que eleva sua centralidade de autovalor a um nível\n",
    "consideravelmente mais alto do que seu baixo grau sugeriria.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "E) Discuta as diferenças entre as duas centralidades à luz dos resultados obtidos.\n",
    "\n",
    "Os resultados desta rede evidenciam a diferença fundamental entre as duas métricas:\n",
    "\n",
    "- Centralidade de Grau: É uma medida de popularidade local, simplesmente contando o NÚMERO de conexões diretas. O nó 6 é o vencedor claro com 7 conexões, \n",
    "enquanto os nós 7-12 são os \"perdedores\" com apenas 1 conexão cada.\n",
    "\n",
    "- Centralidade de Autovalor: É uma medida de influência, que considera a QUALIDADE das conexões. Ela responde à pergunta \"quão importantes são seus vizinhos?\".\n",
    "O nó 6 é o mais influente por conectar os dois principais agrupamentos da rede. Os nós 7-12, apesar de terem poucas conexões, demonstram uma influência significativa (autovalor de ~0.24)\n",
    "porque estão ligados ao nó mais importante.\n",
    "Em resumo, o exercício mostra que um nó não precisa ter muitas conexões para ser influente, desde que suas poucas conexões sejam com os nós certos.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLEV11wfATK3"
   },
   "source": [
    "# **Exerício 5**\n",
    "\n",
    "Em um cenário onde um analista de dados possui uma coleção de documentos textuais de natureza variada — como notícias, publicações em redes sociais, ou descrições de produtos —, surge a necessidade de identificar automaticamente os **principais temas ou tópicos** abordados nesses textos. Tal tarefa é especialmente relevante em contextos onde os dados são não rotulados e o volume de documentos inviabiliza a análise manual.\n",
    "\n",
    "\n",
    "**Objetivo:**\n",
    "Dado um conjunto de 10 manchetes de notícias, aplicar **Análise Semântica Latente (LSA) via SVD** para identificar **temas comuns** (conceitos latentes) e analisar a relevância de palavras e documentos.\n",
    "\n",
    "---\n",
    "\n",
    "# **Conjunto de manchetes**\n",
    "\n",
    "1. Time vence campeonato nacional\n",
    "2. Jogador é destaque na vitória do time\n",
    "3. Equipe perde final em jogo equilibrado\n",
    "4. Treinador elogia desempenho da equipe\n",
    "5. Jogador marca gol decisivo no campeonato\n",
    "6. Time reage e vence partida importante\n",
    "7. Jogador lidera equipe rumo à final\n",
    "8. Equipe conquista vitória histórica\n",
    "9. Treinador anuncia substituição estratégica\n",
    "10. Jogador decide jogo com gol de empate\n",
    "11. Bolsa de valores sobe após anúncio econômico\n",
    "12. Mercado financeiro reage a nova política fiscal\n",
    "13. Inflação preocupa investidores e governo\n",
    "14. Governo anuncia medidas para controlar inflação\n",
    "15. Mercado de ações fecha em alta\n",
    "16. Valores da bolsa aumentam com relatório positivo\n",
    "17. Investidores reagem à decisão do banco central\n",
    "18. Política econômica impacta mercado financeiro\n",
    "19. Inflação e desemprego influenciam investidores\n",
    "20. Governo divulga plano fiscal detalhado\n",
    "\n",
    "\n",
    "\n",
    "**Procedimento matemático**\n",
    "\n",
    " **Representação:**\n",
    "\n",
    "   * Construir uma **matriz termo-documento** $A \\in \\mathbb{R}^{m \\times 10}$, com linhas correspondendo a **palavras relevantes** (substantivos e verbos de ação) e colunas aos documentos.\n",
    "   * Cada elemento $a_{ij}$ indica a presença ou frequência da palavra $i$ no documento $j$.\n",
    "\n",
    " **Decomposição SVD:**\n",
    "   $\n",
    "   A = U  \\Sigma  V^T\n",
    "   $\n",
    "\n",
    "   * $U \\in \\mathbb{R}^{m \\times r}$: indica a participação das palavras nos conceitos latentes\n",
    "   * $\\Sigma \\in \\mathbb{R}^{r \\times r}$: indica a importância de cada conceito\n",
    "   * $V \\in \\mathbb{R}^{10 \\times r}$: indica a participação dos documentos nos conceitos latentes\n",
    "   * $r = \\text{posto}(A)$\n",
    "\n",
    "\n",
    "a) Qual é o tema dominante no conjunto de manchetes? Qual é secundário?\n",
    "\n",
    "b) Quais palavras (substantivos ou verbos) são mais representativas de cada tema? Liste 5 de cada.\n",
    "\n",
    "c) Quais são os 5 documentos mais representativas de cada tema?\n",
    "\n",
    "d) Como os verbos de ação contribuiram para a distinção entre os temas?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ia8BMEku3iqQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTÃO A ----\n",
      "Tema Dominante: 'Inflação'\n",
      "  - Importância (explained variance): 0.28\n",
      "Tema Secundário: 'Jogador'\n",
      "  - Importância (explained variance): 0.26\n",
      "\n",
      "\n",
      "QUESTÃO B ----\n",
      "Palavras associadas ao tema 'Jogador': jogador, equipe, final, gol, jogo\n",
      "Palavras associadas ao tema 'Inflação': inflação, governo, investidores, preocupa, anuncia\n",
      "\n",
      "\n",
      "QUESTÃO C ----\n",
      "Documentos mais representativos do tema 'Jogador':\n",
      "  - (Doc 7) Jogador lidera equipe rumo à final\n",
      "  - (Doc 10) Jogador decide jogo com gol de empate\n",
      "  - (Doc 5) Jogador marca gol decisivo no campeonato\n",
      "  - (Doc 3) Equipe perde final em jogo equilibrado\n",
      "  - (Doc 2) Jogador é destaque na vitória do time\n",
      "Documentos mais representativos do tema 'Inflação':\n",
      "  - (Doc 13) Inflação preocupa investidores e governo\n",
      "  - (Doc 14) Governo anuncia medidas para controlar inflação\n",
      "  - (Doc 19) Inflação e desemprego influenciam investidores\n",
      "  - (Doc 20) Governo divulga plano fiscal detalhado\n",
      "  - (Doc 17) Investidores reagem à decisão do banco central\n",
      "\n",
      "\n",
      "QUESTÃO D ----\n",
      "Os verbos de ação foram fundamentais para a distinção clara entre os temas.\n",
      "A associação semântica entre substantivos pode ser ambígua, mas a combinação de certos pares verbo-substantivo mostram claramente a existência de um certo tema associado.\n",
      "Por exemplo, 'time/vence' e 'jogador/marca' são fortemente ligados ao tema esportivo, enquanto 'bolsa/sobe' e 'governo/anuncia' são claramente econômicos, o que provavelmente seria menos evidente numa análise baseada apenas em substantivos ou verbos.\n"
     ]
    }
   ],
   "source": [
    "# LSA com SVD em 20 manchetes, vocabulário único e verbos de ação\n",
    "from sklearn.feature_extraction.text import CountVectorizer # você pode usar esta função para montar a matriz termo-documento\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# Conjunto de 20 manchetes\n",
    "documents = [\n",
    "    # Esportes\n",
    "    \"Time vence campeonato nacional\",\n",
    "    \"Jogador é destaque na vitória do time\",\n",
    "    \"Equipe perde final em jogo equilibrado\",\n",
    "    \"Treinador elogia desempenho da equipe\",\n",
    "    \"Jogador marca gol decisivo no campeonato\",\n",
    "    \"Time reage e vence partida importante\",\n",
    "    \"Jogador lidera equipe rumo à final\",\n",
    "    \"Equipe conquista vitória histórica\",\n",
    "    \"Treinador anuncia substituição estratégica\",\n",
    "    \"Jogador decide jogo com gol de empate\",\n",
    "    # Economia\n",
    "    \"Bolsa de valores sobe após anúncio econômico\",\n",
    "    \"Mercado financeiro reage a nova política fiscal\",\n",
    "    \"Inflação preocupa investidores e governo\",\n",
    "    \"Governo anuncia medidas para controlar inflação\",\n",
    "    \"Mercado de ações fecha em alta\",\n",
    "    \"Valores da bolsa aumentam com relatório positivo\",\n",
    "    \"Investidores reagem à decisão do banco central\",\n",
    "    \"Política econômica impacta mercado financeiro\",\n",
    "    \"Inflação e desemprego influenciam investidores\",\n",
    "    \"Governo divulga plano fiscal detalhado\"\n",
    "]\n",
    "\n",
    "# Vocabulário restrito a palavras-chave (substantivos + verbos de ação), sem duplicatas\n",
    "vocabulary = [\n",
    "    # Esportes\n",
    "    \"time\", \"jogador\", \"campeonato\", \"vitória\", \"equipe\", \"final\", \"jogo\", \"treinador\", \"gol\",\n",
    "    \"vence\", \"marca\", \"perde\", \"reage\", \"decide\", \"conquista\", \"anuncia\", \"lidera\", \"substituição\",\n",
    "    # Economia\n",
    "    \"bolsa\", \"valores\", \"mercado\", \"financeiro\", \"inflação\", \"investidores\", \"governo\",\n",
    "    \"sobe\", \"preocupa\", \"divulga\", \"impacta\", \"aumentam\", \"decisão\", \"plano\"\n",
    "]\n",
    "\n",
    "#Matriz termo-documento (contagem simples)\n",
    "\n",
    "# Aplicar SVD (LSA)\n",
    "k = 2  # número de temas latentes\n",
    "\n",
    "# Palavras mais importantes por tema\n",
    "n_top_words = 5\n",
    "\n",
    "# Documentos mais associados a cada tema\n",
    "n_top_docs = 5\n",
    "\n",
    "\n",
    "# acima, código predefinido pelo exercício. abaixo, nossa lógica de solução --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# inicializa 'CountVectorizer' com o vocabulário dado; cada linha representa uma palavra do vocabulário, cada coluna representa um documento (manchete)\n",
    "# 'vocabulary=vocabulary': Garante que apenas as palavras da lista sejam consideradas (o primeiro 'vocabulary' é o parâmetro do CountVectorizer)\n",
    "# 'binary=True': Faz com que a contagem seja 0 ou 1 (presente ou ausente), em vez de contar múltiplas ocorrências\n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary, binary=True)\n",
    "\n",
    "# \".fit_transform()\" aprende o vocabulário e transforma os documentos na matriz A\n",
    "A = vectorizer.fit_transform(documents).toarray().T # usamos .T para ter palavras nas linhas e docs nas colunas\n",
    "# print(A) # descomentar para ver a matriz\n",
    "\n",
    "# inicializamos o modelo SVD para encontrar k temas (\"TruncatedSVD\" é uma versão eficiente do SVD, boa para LSA) \n",
    "svd = TruncatedSVD(n_components=k, random_state=0) # setar \"random_state\" fixo garante reprodutibilidade (mantém o mesmo resultado sempre). coloquei 0 por nada em particular\n",
    "\n",
    "# aplicamos o SVD na nossa matriz A; o resultado que nos interessa para os documentos fica no transform\n",
    "# \".fit()\" aprende a decomposição (U, Sigma, V^T), \".transform()\" aplica a decomposição aos dados\n",
    "matriz_documento_tema = svd.fit_transform(A.T) # a entrada deve ser (documentos, palavras), por isso .T no A\n",
    "\n",
    "# cria rótulos para os temas com base nas palavras mais importantes. usado posteriormente para interpretar os temas e imprimir resultados\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "theme_labels = [] # lista para guardar rótulos que serão criados\n",
    "for i, topic in enumerate(svd.components_):\n",
    "    top_words_indices = topic.argsort()[::-1][:n_top_words]\n",
    "    top_words = [feature_names[idx] for idx in top_words_indices]\n",
    "    # cria um rótulo para o tema com base em suas 3 palavras principais\n",
    "    label = f\"'{top_words[0].capitalize()}'\"\n",
    "    theme_labels.append(label)\n",
    "\n",
    "# a) ----------------------- //\n",
    "print(\"\\nQUESTÃO A ----\")\n",
    "# svd.explained_variance_ dá uma medida da importância de cada tema\n",
    "importancia_temas = svd.explained_variance_\n",
    "\n",
    "# identifica qual índice (0 ou 1) tem a maior importância\n",
    "idx_dominante = np.argmax(importancia_temas)\n",
    "idx_secundario = np.argmin(importancia_temas)\n",
    "\n",
    "print(f\"Tema Dominante: {theme_labels[idx_dominante]}\")\n",
    "print(f\"  - Importância (explained variance): {importancia_temas[idx_dominante]:.2f}\")\n",
    "\n",
    "print(f\"Tema Secundário: {theme_labels[idx_secundario]}\")\n",
    "print(f\"  - Importância (explained variance): {importancia_temas[idx_secundario]:.2f}\\n\")\n",
    "\n",
    "# b) ----------------------- //\n",
    "print(\"\\nQUESTÃO B ----\")\n",
    "\n",
    "for i, label in enumerate(theme_labels):\n",
    "    # reutiliza a lógica anterior para pegar as 5 palavras (n_top_words) associadas ao tema\n",
    "    topic = svd.components_[i]\n",
    "    top_words_indices = topic.argsort()[::-1][:n_top_words]\n",
    "    top_words = [feature_names[idx] for idx in top_words_indices]\n",
    "    print(f\"Palavras associadas ao tema {label}: {', '.join(top_words)}\")\n",
    "print()\n",
    "\n",
    "# c) ----------------------- //\n",
    "print(\"\\nQUESTÃO C ----\")\n",
    "# para cada tema (coluna da matriz_documento_tema), encontra os índices dos documentos (linhas) com os maiores valores\n",
    "for i, label in enumerate(theme_labels):\n",
    "    # .argsort()[::-1] ordena os índices dos documentos do mais relevante para o menos relevante\n",
    "    top_docs_indices = matriz_documento_tema[:, i].argsort()[::-1][:n_top_docs]\n",
    "    print(f\"Documentos mais representativos do tema {label}:\")\n",
    "    for doc_idx in top_docs_indices:\n",
    "        print(f\"  - (Doc {doc_idx+1}) {documents[doc_idx]}\")\n",
    "print()\n",
    "\n",
    "# d) ----------------------- //\n",
    "print(\"\\nQUESTÃO D ----\")\n",
    "print(\"Os verbos de ação foram fundamentais para a distinção clara entre os temas.\")\n",
    "print(\"A associação semântica entre substantivos pode ser ambígua, mas a combinação de certos pares verbo-substantivo mostram claramente a existência de um certo tema associado.\")\n",
    "print(\"Por exemplo, 'time/vence' e 'jogador/marca' são fortemente ligados ao tema esportivo, enquanto 'bolsa/sobe' e 'governo/anuncia' são claramente econômicos, o que provavelmente seria menos evidente numa análise baseada apenas em substantivos ou verbos.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
